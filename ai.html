<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-11-17 Mon 01:32 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>AI in 2025</title>
<meta name="author" content="jbh" />
<meta name="generator" content="Org Mode" />
<style type="text/css">
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<style> body {background-color: #fafad2; max-width: 62.5rem; padding: 1rem; margin: auto;} </style>
</head>
<body>
<div id="content" class="content">
<h1 class="title">AI in 2025</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org69d486a">Intro</a></li>
<li><a href="#org337f2df">Curriculum</a>
<ul>
<li>
<ul>
<li><a href="#org58dabaf">Research</a></li>
</ul>
</li>
<li><a href="#orgdb93b09">Theory</a>
<ul>
<li><a href="#org7ca032f">Advanced Introduction to ML</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org9f41216">Start Here: Scalar Calculus</a></li>
<li><a href="#org470c043">Linear Algebra</a></li>
<li><a href="#org76e186b"><span class="todo TODO">TODO</span> Gradient</a></li>
<li><a href="#orgfd52d43"><span class="todo TODO">TODO</span> Matrix Calculus</a></li>
</ul>
</div>
</div>
<div id="outline-container-org69d486a" class="outline-2">
<h2 id="org69d486a">Intro</h2>
<div class="outline-text-2" id="text-org69d486a">
<p>
We will learn the 'full stack' of modern deep learning systems by building our own library from scratch and how to reverse engineer them. Neural networks have different architectures just like there is different computer hardware architectures (x86, RISC, ARM). The most popular currently is transformer architecture for large language models (Grok-n, GPT-n) but regular old neural networks learning some function continue to be useful in every field the game is not over with advanced LLMs.
</p>

<p>
<b>Limits of AI</b>
</p>

<p>
Current popular AI is all <a href="https://en.wikipedia.org/wiki/Foundation_model">foundation models</a> like Grok-n, GPT-n, DALL-E etc. Have you wondered if we had infinite resources, infinite data, perfect training algorithms with no errors (aka ideal models), can we use this type of model for everything aka 'General AI'? Someone with help from the Beijing Academy of AI used <a href="https://proceedings.mlr.press/v202/yuan23b.html">category theory</a> to model this scenario to see what is possible.  
</p>
</div>
</div>
<div id="outline-container-org337f2df" class="outline-2">
<h2 id="org337f2df">Curriculum</h2>
<div class="outline-text-2" id="text-org337f2df">
<p>
Build an AI framework:
</p>

<ul class="org-ul">
<li><a href="https://dlsyscourse.org">10-714 DL Algorithms &amp; Implementation</a> (CMU)
<ul class="org-ul">
<li>Build from scratch an entire framework for deep learning</li>
<li>References to use as we go:
<ul class="org-ul">
<li><a href="https://introml.mit.edu/notes/">notes</a> (MIT)</li>
<li><a href="https://jorchard.github.io/cs479.github.io/index.html">short lectures</a> from the perspective of theoretical neuroscience</li>
<li><a href="https://udlbook.github.io/udlbook/">book</a> <i>Understanding Deep Learning</i></li>
</ul></li>
</ul></li>
</ul>

<p>
Fuse the framework with multimodal capabilities:
</p>

<ul class="org-ul">
<li><a href="https://mit-mi.github.io/how2ai-course/spring2025/">MAS.S60 How2AI</a> (MIT)
<ul class="org-ul">
<li>How to AI (Almost) Anything</li>
<li>YouTube <a href="https://www.youtube.com/playlist?list=PLc0Yh0D0XR4Z3wityRaEuu4rfzTHRIIAO">lectures</a></li>
</ul></li>
</ul>
</div>
<div id="outline-container-org58dabaf" class="outline-4">
<h4 id="org58dabaf">Research</h4>
<div class="outline-text-4" id="text-org58dabaf">
<p>
We learn some of the applied art of attempting to reverse engineer or at least understand what an AI model is actually doing like if it's lying to us or has some emergent abilities. 
</p>

<ul class="org-ul">
<li><a href="https://www.neelnanda.io/mechanistic-interpretability/getting-started">Mechanistic Interpretability</a> (Neel Nanda@Google DeepMind)
<ul class="org-ul">
<li>Complete guide to doing research yourself in mech interp</li>
<li>Example material is <a href="https://github.com/callummcdougall/ARENA_3.0/tree/main">here</a> and 90% programming
<ul class="org-ul">
<li>Chapter <a href="https://arena-chapter0-fundamentals.streamlit.app/">0</a></li>
<li>Chapter <a href="https://arena-chapter1-transformer-interp.streamlit.app/">1</a></li>
<li>Chapter <a href="https://arena-chapter2-rl.streamlit.app/">2</a></li>
<li>Chapter <a href="https://arena-chapter3-llm-evals.streamlit.app/">3</a></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgdb93b09" class="outline-3">
<h3 id="orgdb93b09">Theory</h3>
<div class="outline-text-3" id="text-orgdb93b09">
<p>
The PhD <a href="https://ml.cmu.edu/current-students/phd-curriculum">core requirements</a> of most schools consists of:
</p>
<ul class="org-ul">
<li>The mathematical theory of ML (supervised learning is statistical decision theory)</li>
<li>Models that generate their own learning samples (diffusion/GANs)</li>
<li>Optimizing some function under a set of constraints (non and convex, distributed)</li>
<li>The mathematical model of RL and multi-armed bandits (decisions under uncertainty)</li>
<li>A bunch of higher dimensional probability/stats we won't take here</li>
<li>Causality</li>
</ul>

<p>
The goal is then to figure out how to improve or come up with a better model/optimizer and there's an endless stream of daily papers from around the world doing just that being dumped on arxiv or published in various ML journals. 
</p>

<p>
Any AI doctor or robot space pilot is going to come from a causal learning model in fact every interesting problem you want predicted by AI is almost certainly a causal question like 'if I set this to X, will Y happen?' and 'what would've happened if I did Z instead of X'.
</p>
</div>
<div id="outline-container-org7ca032f" class="outline-4">
<h4 id="org7ca032f">Advanced Introduction to ML</h4>
<div class="outline-text-4" id="text-org7ca032f">
<p>
Here is the same content as <a href="https://www.cs.cmu.edu/~nihars/teaching/10715Fa25.html">10-715</a> or the mathematical model of machine learning in 2025 (which is mostly just a bunch of graphs which themselves are mostly DAGs) 
</p>


<ul class="org-ul">
<li><a href="https://student.cs.uwaterloo.ca/~cs485/">CS 485 Theory of ML</a> (Waterloo)   
<ul class="org-ul">
<li>All the <a href="https://www.youtube.com/playlist?list=PLt6ES1TJ1gtsvVE_jD-nYaxB2yJzk4zNB">lectures</a> taught by the author of the <a href="https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/index.html">book</a></li>
<li><a href="https://diffusion.csail.mit.edu/">MIS 6.S184 Diffusion Models</a> 6 lectures on the math of diffusion models</li>
<li><a href="https://arxiv.org/pdf/1904.07272">Multi-Armed Bandits</a> or <a href="https://rltheorybook.github.io/">RL: Theory and Algorithms</a> though we won't take all of this</li>
<li><a href="https://library.oapen.org/bitstream/id/056a11be-ce3a-44b9-8987-a6c68fce8d9b/11283.pdf">Elements of Causal Inference</a> Foundations and learning algorithms</li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org9f41216" class="outline-2">
<h2 id="org9f41216">Start Here: Scalar Calculus</h2>
<div class="outline-text-2" id="text-org9f41216">
<p>
The math we are doing is not symbolic it's all numerical/analytical so it can be run on a computer system. We're just going to learn the math needed as we go.
</p>

<ul class="org-ul">
<li>Watch this <a href="https://youtu.be/9vKqVkMQHKk?si=-MetxfKULGKCQhqU">derivative</a> video by 3Blue1Brown which explains the dy/dx notation.</li>
</ul>

<p>
Anything that accumulates (speed, volume, interest, distance, produced units) has a function of the rate of how fast it is accumulating. In that 3Blue1Brown video distance traveled is an accumulation and the velocity (speed in scalar calculus) is the rate of that distance accumulation. Speed also accumulates because it is measured in m/s or mp/h so it too has a rate of change function called acceleration. You can switch between both functions so recover the velocity function from acceleration by integrating which we'll learn when it comes up.
</p>
</div>
</div>
<div id="outline-container-org470c043" class="outline-2">
<h2 id="org470c043">Linear Algebra</h2>
<div class="outline-text-2" id="text-org470c043">
<p>
Watch from the <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Essence of linear algebra</a> playlist: 
</p>
<ul class="org-ul">
<li>Vectors</li>
<li>Linear combinations</li>
<li>Linear transformations</li>
<li>Matrix mulitplication as composition</li>
<li>Nonsquare matrices as transformations between dimensions</li>
</ul>

<p>
Look up on youtube what a transpose is or x<sup>T</sup> we will see all this in depth shortly. 
</p>
</div>
</div>
<div id="outline-container-org76e186b" class="outline-2">
<h2 id="org76e186b"><span class="todo TODO">TODO</span> Gradient</h2>
</div>

<div id="outline-container-orgfd52d43" class="outline-2">
<h2 id="orgfd52d43"><span class="todo TODO">TODO</span> Matrix Calculus</h2>
<div class="outline-text-2" id="text-orgfd52d43">
<ul class="org-ul">
<li><a href="https://ocw.mit.edu/courses/18-s096-matrix-calculus-for-machine-learning-and-beyond-january-iap-2023/">Matrix Calculus</a> (MIT)
<ul class="org-ul">
<li>8 lectures on calculus generalized to higher dimensions none of it will be symbolic</li>
</ul></li>
</ul>

<hr />
<p>
<a href="./index.html">Home</a>
</p>
</div>
</div>
</div>
</body>
</html>
